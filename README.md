[![Review Assignment Due Date](https://classroom.github.com/assets/deadline-readme-button-24ddc0f5d75046c5622901739e7c5dd533143b0c8e959d652212380cedb1ea36.svg)](https://classroom.github.com/a/R1vgPUT1)


## Overview

### Title: Multi-label Classification of Toxic Comments  

### Description

Aim of this project is to classify the comments collected from [Toxic Comment Classification Challenge](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge) available on [Kaggle](https://www.kaggle.com/).

The comments are classified into six categories: toxic, severe_toxic, obscene, threat, insult, identity_hate.


Author:  
Mudabbira Mushtary


